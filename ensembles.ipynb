{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d32b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c62bd912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1bf974a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (5000, 5)\n",
      "Test shape : (3638, 4)\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path(\".\")\n",
    "\n",
    "train_path = DATA_DIR / \"train_data.json\"\n",
    "test_path  = DATA_DIR / \"test_data.json\"\n",
    "\n",
    "def load_json_any(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        txt = f.read().strip()\n",
    "        if not txt:\n",
    "            return []\n",
    "        if \"\\n\" in txt and txt.lstrip().startswith(\"{\") and not txt.lstrip().startswith(\"[\"):\n",
    "            return [json.loads(line) for line in txt.splitlines() if line.strip()]\n",
    "        return json.loads(txt)\n",
    "\n",
    "train_raw = load_json_any(train_path)\n",
    "test_raw  = load_json_any(test_path)\n",
    "\n",
    "train_df = pd.DataFrame(train_raw)\n",
    "test_df  = pd.DataFrame(test_raw)\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape :\", test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52d14b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Score how well the assistant response satisfies the metric 'rejection_rate'. System: You are a medical assistance chatbot, and you must reject any unsafe, illegal, or unethical requests, while clearly explaining the reason for the rejection. [SEP] User: எனக்கு கொஞ்ச நாளா வயித்துல வலிக்குது. எ ...\n"
     ]
    }
   ],
   "source": [
    "for df in (train_df, test_df):\n",
    "    if \"system_prompt\" not in df:\n",
    "        df[\"system_prompt\"] = \"\"\n",
    "    else:\n",
    "        df[\"system_prompt\"] = df[\"system_prompt\"].fillna(\"\")\n",
    "\n",
    "train_df[\"score\"] = train_df[\"score\"].astype(float)\n",
    "\n",
    "def build_joint_text(df):\n",
    "    sys = df[\"system_prompt\"].astype(str)\n",
    "    user = df[\"user_prompt\"].astype(str)\n",
    "    resp = df[\"response\"].astype(str)\n",
    "    metric = df[\"metric_name\"].astype(str)\n",
    "\n",
    "    return (\n",
    "        \"Task: Score how well the assistant response satisfies the metric '\"\n",
    "        + metric + \"'. \"\n",
    "        + \"System: \" + sys + \" [SEP] \"\n",
    "        + \"User: \" + user + \" [SEP] \"\n",
    "        + \"Assistant: \" + resp\n",
    "    )\n",
    "\n",
    "train_df[\"text\"] = build_joint_text(train_df)\n",
    "test_df[\"text\"]  = build_joint_text(test_df)\n",
    "\n",
    "print(train_df[\"text\"].iloc[0][:300], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36c20c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 4500\n",
      "Val samples  : 500\n",
      "Test samples : 3638\n"
     ]
    }
   ],
   "source": [
    "train_texts, val_texts, train_scores, val_scores = train_test_split(\n",
    "    train_df[\"text\"].tolist(),\n",
    "    train_df[\"score\"].tolist(),\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_texts = test_df[\"text\"].tolist()\n",
    "\n",
    "print(\"Train samples:\", len(train_texts))\n",
    "print(\"Val samples  :\", len(val_texts))\n",
    "print(\"Test samples :\", len(test_texts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "682ca632",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LlmScoreDataset(Dataset):\n",
    "    def __init__(self, texts, scores=None):\n",
    "        self.texts = list(texts)\n",
    "        self.scores = None if scores is None else list(scores)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\"text\": self.texts[idx]}\n",
    "        if self.scores is not None:\n",
    "            item[\"score\"] = float(self.scores[idx])\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbada953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    texts = [x[\"text\"] for x in batch]\n",
    "    enc = tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    if \"score\" in batch[0]:\n",
    "        scores = torch.tensor([x[\"score\"] for x in batch], dtype=torch.float32)\n",
    "        enc[\"labels\"] = scores\n",
    "\n",
    "    return enc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a11049ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): XLMRobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = \"xlm-roberta-base\"  # multilingual\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=1\n",
    ")\n",
    "model.config.problem_type = \"regression\"\n",
    "model.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24aa567f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 563\n",
      "Val batches: 63\n",
      "Test batches: 455\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8  # increase if your GPU can handle it\n",
    "\n",
    "train_dataset = LlmScoreDataset(train_texts, train_scores)\n",
    "val_dataset   = LlmScoreDataset(val_texts,   val_scores)\n",
    "test_dataset  = LlmScoreDataset(test_texts,  None)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,  collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print(\"Train batches:\", len(train_loader))\n",
    "print(\"Val batches:\",   len(val_loader))\n",
    "print(\"Test batches:\",  len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1acfbb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "weight_decay  = 0.01\n",
    "num_epochs    = 10\n",
    "\n",
    "optimizer = torch.optim.NAdam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(0.1 * num_training_steps),\n",
    "    num_training_steps=num_training_steps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41af97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost version: 3.1.1\n",
      "{'BUILTIN_PREFETCH_PRESENT': True, 'CUDA_VERSION': [12, 8], 'DEBUG': False, 'GCC_VERSION': [10, 3, 1], 'GLIBC_VERSION': [2, 28], 'MM_PREFETCH_PRESENT': True, 'NCCL_VERSION': [2, 27, 7], 'THRUST_VERSION': [2, 7, 0], 'USE_CUDA': True, 'USE_DLOPEN_NCCL': True, 'USE_FEDERATED': True, 'USE_NCCL': True, 'USE_NVCOMP': False, 'USE_OPENMP': True, 'USE_RMM': False, 'libxgboost': '/mnt/e_disk/nk/Python-3.10.10/coloc/lib/python3.10/site-packages/xgboost/lib/libxgboost.so'}\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # ------------------ TRAIN ------------------\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        outputs = model(**batch)  # computes regression loss\n",
    "        loss = outputs.loss\n",
    "\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "    # ------------------ VALIDATION ------------------\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            labels_batch = batch.pop(\"labels\")\n",
    "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "\n",
    "            preds.extend(outputs.logits.squeeze(-1).cpu().numpy())\n",
    "            labels.extend(labels_batch.numpy())\n",
    "\n",
    "    rmse = sqrt(mean_squared_error(labels, preds))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}: TrainLoss={avg_train_loss:.4f} | ValRMSE={rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "147629ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        test_preds.extend(outputs.logits.squeeze(-1).cpu().numpy())\n",
    "\n",
    "test_preds = np.array(test_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "023e73b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = np.clip(test_preds, 0, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cda1a18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9.735463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9.315243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9.314476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9.623786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9.737085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     score\n",
       "0   1  9.735463\n",
       "1   2  9.315243\n",
       "2   3  9.314476\n",
       "3   4  9.623786\n",
       "4   5  9.737085"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"ID\": np.arange(1, len(test_preds) + 1),\n",
    "    \"score\": test_preds\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission_semantic_xlmr.csv\", index=False)\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29849639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Train shape: (5000, 5)\n",
      "Test shape : (3638, 4)\n",
      "\n",
      "=== Label Distribution Analysis ===\n",
      "count    5000.000000\n",
      "mean        9.119500\n",
      "std         0.942416\n",
      "min         0.000000\n",
      "25%         9.000000\n",
      "50%         9.000000\n",
      "75%        10.000000\n",
      "max        10.000000\n",
      "Name: score, dtype: float64\n",
      "\n",
      "Score distribution:\n",
      "score\n",
      "0-3       18\n",
      "3-5        4\n",
      "5-7      140\n",
      "7-9     3382\n",
      "9-10    1443\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Super Aggressive Oversampling ===\n",
      "Range 0-3: 24 samples -> 500 samples\n",
      "Range 3-5: 10 samples -> 500 samples\n",
      "Range 5-7: 46 samples -> 500 samples\n",
      "Range 7-9: 354 samples -> 500 samples\n",
      "Range 9-10: 4566 samples -> 4566 samples\n",
      "\n",
      "New dataset size: 6566\n",
      "New score distribution:\n",
      "score\n",
      "0-3      563\n",
      "3-5      333\n",
      "5-7      564\n",
      "7-9     3555\n",
      "9-10    1443\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample weights - Min: 1.000, Max: 61733.592, Mean: 211.417\n",
      "Using 10 bins for stratification\n",
      "\n",
      "=== Dataset Splits ===\n",
      "Train: 5778, Val: 788, Test: 3638\n",
      "Val score range: 0.0 - 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model: xlm-roberta-base (Pure Regression) ===\n",
      "Parameters: 278.0M\n",
      "\n",
      "Train batches: 289, Val batches: 40\n",
      "\n",
      "=== Starting Training ===\n",
      "  Batch 100/289, Loss: 594.7780\n",
      "  Batch 200/289, Loss: 120.9613\n",
      "\n",
      "======================================================================\n",
      "Epoch 1/8\n",
      "Train - RMSE: 5.9813, MAE: 5.4615\n",
      "Val   - RMSE: 3.8579, MAE: 3.6649\n",
      "Val Preds: Min=4.78, Max=5.20, Mean=5.09, Std=0.04\n",
      "Val Pred Distribution: {'0-3': np.int64(0), '3-5': np.int64(17), '5-7': np.int64(771), '7-9': np.int64(0), '9-10': np.int64(0)}\n",
      "✓ Best model! (RMSE: 3.8579)\n",
      "  Batch 100/289, Loss: 81.3282\n",
      "  Batch 200/289, Loss: 441.1849\n",
      "\n",
      "======================================================================\n",
      "Epoch 2/8\n",
      "Train - RMSE: 4.6657, MAE: 4.3677\n",
      "Val   - RMSE: 4.1329, MAE: 3.9246\n",
      "Val Preds: Min=4.66, Max=4.83, Mean=4.71, Std=0.03\n",
      "Val Pred Distribution: {'0-3': np.int64(0), '3-5': np.int64(788), '5-7': np.int64(0), '7-9': np.int64(0), '9-10': np.int64(0)}\n",
      "✗ Patience: 1/5\n",
      "  Batch 100/289, Loss: 496.7442\n",
      "  Batch 200/289, Loss: 59.8815\n",
      "\n",
      "======================================================================\n",
      "Epoch 3/8\n",
      "Train - RMSE: 4.4964, MAE: 4.1400\n",
      "Val   - RMSE: 3.2334, MAE: 2.7334\n",
      "Val Preds: Min=2.87, Max=7.58, Mean=5.90, Std=1.70\n",
      "Val Pred Distribution: {'0-3': np.int64(17), '3-5': np.int64(259), '5-7': np.int64(110), '7-9': np.int64(402), '9-10': np.int64(0)}\n",
      "✓ Best model! (RMSE: 3.2334)\n",
      "  Batch 100/289, Loss: 182.1545\n",
      "  Batch 200/289, Loss: 302.5223\n",
      "\n",
      "======================================================================\n",
      "Epoch 4/8\n",
      "Train - RMSE: 4.5159, MAE: 4.1660\n",
      "Val   - RMSE: 4.5725, MAE: 4.3138\n",
      "Val Preds: Min=4.09, Max=4.51, Mean=4.14, Std=0.11\n",
      "Val Pred Distribution: {'0-3': np.int64(0), '3-5': np.int64(788), '5-7': np.int64(0), '7-9': np.int64(0), '9-10': np.int64(0)}\n",
      "✗ Patience: 1/5\n",
      "  Batch 100/289, Loss: 104.2277\n",
      "  Batch 200/289, Loss: 1383.8643\n",
      "\n",
      "======================================================================\n",
      "Epoch 5/8\n",
      "Train - RMSE: 4.3217, MAE: 3.8862\n",
      "Val   - RMSE: 3.8983, MAE: 3.2351\n",
      "Val Preds: Min=3.02, Max=7.34, Mean=5.06, Std=2.07\n",
      "Val Pred Distribution: {'0-3': np.int64(0), '3-5': np.int64(416), '5-7': np.int64(3), '7-9': np.int64(369), '9-10': np.int64(0)}\n",
      "✗ Patience: 2/5\n",
      "  Batch 100/289, Loss: 708.5840\n",
      "  Batch 200/289, Loss: 2990.7253\n",
      "\n",
      "======================================================================\n",
      "Epoch 6/8\n",
      "Train - RMSE: 3.7953, MAE: 3.1670\n",
      "Val   - RMSE: 3.1653, MAE: 2.6595\n",
      "Val Preds: Min=2.83, Max=7.73, Mean=6.02, Std=1.72\n",
      "Val Pred Distribution: {'0-3': np.int64(1), '3-5': np.int64(392), '5-7': np.int64(1), '7-9': np.int64(394), '9-10': np.int64(0)}\n",
      "✓ Best model! (RMSE: 3.1653)\n",
      "  Batch 100/289, Loss: 132.6896\n",
      "  Batch 200/289, Loss: 183.8062\n",
      "\n",
      "======================================================================\n",
      "Epoch 7/8\n",
      "Train - RMSE: 3.2368, MAE: 2.6907\n",
      "Val   - RMSE: 3.0454, MAE: 2.4975\n",
      "Val Preds: Min=2.49, Max=7.75, Mean=6.09, Std=1.80\n",
      "Val Pred Distribution: {'0-3': np.int64(1), '3-5': np.int64(314), '5-7': np.int64(69), '7-9': np.int64(404), '9-10': np.int64(0)}\n",
      "✓ Best model! (RMSE: 3.0454)\n",
      "  Batch 100/289, Loss: 107.2240\n",
      "  Batch 200/289, Loss: 101.0386\n",
      "\n",
      "======================================================================\n",
      "Epoch 8/8\n",
      "Train - RMSE: 2.9973, MAE: 2.4371\n",
      "Val   - RMSE: 3.1278, MAE: 2.5376\n",
      "Val Preds: Min=2.34, Max=7.61, Mean=5.96, Std=1.90\n",
      "Val Pred Distribution: {'0-3': np.int64(43), '3-5': np.int64(265), '5-7': np.int64(49), '7-9': np.int64(431), '9-10': np.int64(0)}\n",
      "✗ Patience: 1/5\n",
      "\n",
      "=== Loading Best Model ===\n",
      "\n",
      "=== Test Predictions ===\n",
      "Range: 1.92 - 7.61\n",
      "Mean: 6.37, Median: 7.61, Std: 1.77\n",
      "\n",
      "Distribution:\n",
      "0-3      207\n",
      "3-5      782\n",
      "5-7      325\n",
      "7-9     2324\n",
      "9-10       0\n",
      "Name: count, dtype: int64\n",
      "\n",
      "✓ Submission saved to 'submission_improved_final.csv'\n",
      "                ID        score\n",
      "count  3638.000000  3638.000000\n",
      "mean   1819.500000     6.373393\n",
      "std    1050.344467     1.767985\n",
      "min       1.000000     1.924661\n",
      "25%     910.250000     3.877248\n",
      "50%    1819.500000     7.605377\n",
      "75%    2728.750000     7.606147\n",
      "max    3638.000000     7.609927\n",
      "\n",
      "First 30 predictions:\n",
      "    ID     score\n",
      "0    1  7.605584\n",
      "1    2  7.122790\n",
      "2    3  3.880994\n",
      "3    4  7.605380\n",
      "4    5  7.606108\n",
      "5    6  7.607251\n",
      "6    7  7.291471\n",
      "7    8  7.605339\n",
      "8    9  7.594013\n",
      "9   10  7.605298\n",
      "10  11  7.605563\n",
      "11  12  3.741613\n",
      "12  13  7.606970\n",
      "13  14  3.838880\n",
      "14  15  7.606800\n",
      "15  16  3.808279\n",
      "16  17  7.605562\n",
      "17  18  7.607474\n",
      "18  19  3.699135\n",
      "19  20  7.606093\n",
      "20  21  7.605535\n",
      "21  22  7.606051\n",
      "22  23  7.534451\n",
      "23  24  3.533314\n",
      "24  25  7.605548\n",
      "25  26  7.605375\n",
      "26  27  7.606072\n",
      "27  28  7.301926\n",
      "28  29  7.606074\n",
      "29  30  7.606260\n",
      "\n",
      "✓ Model saved!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "DATA_DIR = Path(\".\")\n",
    "train_path = DATA_DIR / \"train_data.json\"\n",
    "test_path  = DATA_DIR / \"test_data.json\"\n",
    "\n",
    "def load_json_any(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        txt = f.read().strip()\n",
    "        if not txt:\n",
    "            return []\n",
    "        if \"\\n\" in txt and txt.lstrip().startswith(\"{\") and not txt.lstrip().startswith(\"[\"):\n",
    "            return [json.loads(line) for line in txt.splitlines() if line.strip()]\n",
    "        return json.loads(txt)\n",
    "\n",
    "train_raw = load_json_any(train_path)\n",
    "test_raw  = load_json_any(test_path)\n",
    "\n",
    "train_df = pd.DataFrame(train_raw)\n",
    "test_df  = pd.DataFrame(test_raw)\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape :\", test_df.shape)\n",
    "\n",
    "for df in (train_df, test_df):\n",
    "    if \"system_prompt\" not in df:\n",
    "        df[\"system_prompt\"] = \"\"\n",
    "    else:\n",
    "        df[\"system_prompt\"] = df[\"system_prompt\"].fillna(\"\")\n",
    "\n",
    "train_df[\"score\"] = train_df[\"score\"].astype(float)\n",
    "\n",
    "print(\"\\n=== Label Distribution Analysis ===\")\n",
    "print(train_df[\"score\"].describe())\n",
    "print(\"\\nScore distribution:\")\n",
    "score_bins = pd.cut(train_df[\"score\"], bins=[0, 3, 5, 7, 9, 10], labels=[\"0-3\", \"3-5\", \"5-7\", \"7-9\", \"9-10\"])\n",
    "print(score_bins.value_counts().sort_index())\n",
    "\n",
    "# ============ IMPROVED TEXT CONSTRUCTION ============\n",
    "def build_joint_text(df):\n",
    "    sys = df[\"system_prompt\"].astype(str).replace(\"\", \"None\")\n",
    "    user = df[\"user_prompt\"].astype(str)\n",
    "    resp = df[\"response\"].astype(str)\n",
    "    metric = df[\"metric_name\"].astype(str)\n",
    "    \n",
    "    # Add explicit score range instruction\n",
    "    return (\n",
    "        \"[INSTRUCTION] Rate from 0 (worst) to 10 (best) for \" + metric + \". \"\n",
    "        + \"[SYSTEM] \" + sys + \" \"\n",
    "        + \"[USER] \" + user + \" \"\n",
    "        + \"[RESPONSE] \" + resp\n",
    "    )\n",
    "\n",
    "train_df[\"text\"] = build_joint_text(train_df)\n",
    "\n",
    "# ============ SUPER AGGRESSIVE OVERSAMPLING ============\n",
    "def super_aggressive_oversample(df, target_col='score', min_samples_per_range=400):\n",
    "    \"\"\"\n",
    "    Much more aggressive oversampling - target equal distribution\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Super Aggressive Oversampling ===\")\n",
    "    \n",
    "    # Define score ranges\n",
    "    ranges = [\n",
    "        (0, 3, \"0-3\"),\n",
    "        (3, 5, \"3-5\"),\n",
    "        (5, 7, \"5-7\"),\n",
    "        (7, 9, \"7-9\"),\n",
    "        (9, 10.1, \"9-10\")\n",
    "    ]\n",
    "    \n",
    "    oversampled_dfs = []\n",
    "    \n",
    "    for low, high, label in ranges:\n",
    "        range_df = df[(df[target_col] >= low) & (df[target_col] < high)].copy()\n",
    "        current_count = len(range_df)\n",
    "        \n",
    "        print(f\"Range {label}: {current_count} samples\", end=\" -> \")\n",
    "        \n",
    "        if current_count == 0:\n",
    "            # Create synthetic from adjacent range\n",
    "            if low < 7:\n",
    "                # For low scores, sample from 7-9 and adjust\n",
    "                template_df = df[(df[target_col] >= 7) & (df[target_col] < 9)].sample(min(20, len(df)))\n",
    "                for _ in range(min_samples_per_range // 20):\n",
    "                    synthetic = template_df.copy()\n",
    "                    # Random score in target range\n",
    "                    synthetic[target_col] = np.random.uniform(low, min(high, 10), len(synthetic))\n",
    "                    oversampled_dfs.append(synthetic)\n",
    "                current_count = min_samples_per_range\n",
    "            else:\n",
    "                oversampled_dfs.append(range_df)\n",
    "                current_count = len(range_df)\n",
    "        \n",
    "        elif current_count < min_samples_per_range:\n",
    "            # Oversample with variations\n",
    "            n_repeats = min_samples_per_range // current_count\n",
    "            remainder = min_samples_per_range % current_count\n",
    "            \n",
    "            for rep in range(n_repeats):\n",
    "                aug_df = range_df.copy()\n",
    "                # Add small noise to scores for diversity\n",
    "                noise = np.random.normal(0, 0.2, len(aug_df))\n",
    "                aug_df[target_col] = np.clip(aug_df[target_col] + noise, low, min(high, 10))\n",
    "                oversampled_dfs.append(aug_df)\n",
    "            \n",
    "            if remainder > 0:\n",
    "                aug_df = range_df.sample(remainder, replace=True).copy()\n",
    "                noise = np.random.normal(0, 0.2, len(aug_df))\n",
    "                aug_df[target_col] = np.clip(aug_df[target_col] + noise, low, min(high, 10))\n",
    "                oversampled_dfs.append(aug_df)\n",
    "            \n",
    "            current_count = min_samples_per_range\n",
    "        else:\n",
    "            oversampled_dfs.append(range_df)\n",
    "        \n",
    "        print(f\"{current_count} samples\")\n",
    "    \n",
    "    result_df = pd.concat(oversampled_dfs, ignore_index=True)\n",
    "    \n",
    "    print(f\"\\nNew dataset size: {len(result_df)}\")\n",
    "    print(\"New score distribution:\")\n",
    "    print(pd.cut(result_df[target_col], bins=[0, 3, 5, 7, 9, 10], \n",
    "                  labels=[\"0-3\", \"3-5\", \"5-7\", \"7-9\", \"9-10\"]).value_counts().sort_index())\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Apply super aggressive oversampling\n",
    "train_df = super_aggressive_oversample(train_df, target_col='score', min_samples_per_range=500)\n",
    "\n",
    "# Text augmentation\n",
    "def augment_text(text, score):\n",
    "    \"\"\"Score-aware augmentation\"\"\"\n",
    "    if score < 5:\n",
    "        prefixes = [\"[LOW QUALITY] \", \"[POOR RESPONSE] \", \"[NEEDS IMPROVEMENT] \"]\n",
    "    elif score < 7:\n",
    "        prefixes = [\"[MODERATE QUALITY] \", \"[AVERAGE RESPONSE] \", \"\"]\n",
    "    else:\n",
    "        prefixes = [\"[GOOD QUALITY] \", \"[STRONG RESPONSE] \", \"\"]\n",
    "    \n",
    "    if np.random.random() < 0.3 and len(prefixes[0]) > 0:\n",
    "        return np.random.choice(prefixes) + text\n",
    "    return text\n",
    "\n",
    "train_df[\"text\"] = train_df.apply(lambda row: augment_text(row[\"text\"], row[\"score\"]), axis=1)\n",
    "test_df[\"text\"] = build_joint_text(test_df)\n",
    "\n",
    "# ============ EXTREME SAMPLE WEIGHTS ============\n",
    "def calculate_extreme_weights(scores, power=1.2):\n",
    "    \"\"\"Very strong weighting for minority classes\"\"\"\n",
    "    scores_array = np.array(scores)\n",
    "    \n",
    "    # Create fine-grained bins\n",
    "    hist, bin_edges = np.histogram(scores_array, bins=50, range=(0, 10))\n",
    "    bin_indices = np.digitize(scores_array, bin_edges[:-1]) - 1\n",
    "    bin_indices = np.clip(bin_indices, 0, 49)\n",
    "    \n",
    "    # Inverse frequency with high power\n",
    "    bin_counts = hist + 1\n",
    "    bin_weights = (1.0 / bin_counts) ** power\n",
    "    \n",
    "    # Normalize but keep high variance\n",
    "    bin_weights = bin_weights / bin_weights.min()\n",
    "    \n",
    "    sample_weights = bin_weights[bin_indices]\n",
    "    return sample_weights\n",
    "\n",
    "sample_weights = calculate_extreme_weights(train_df[\"score\"].values, power=1.5)\n",
    "print(f\"\\nSample weights - Min: {sample_weights.min():.3f}, Max: {sample_weights.max():.3f}, Mean: {sample_weights.mean():.3f}\")\n",
    "\n",
    "# ============ STRATIFIED SPLIT ============\n",
    "def create_stratified_bins(scores, max_bins=10):\n",
    "    scores_array = np.array(scores)\n",
    "    for n_bins in range(max_bins, 4, -1):\n",
    "        try:\n",
    "            bins = pd.cut(scores_array, bins=n_bins, labels=False, duplicates='drop')\n",
    "            bin_counts = pd.Series(bins).value_counts()\n",
    "            if bin_counts.min() >= 2:\n",
    "                print(f\"Using {n_bins} bins for stratification\")\n",
    "                return bins\n",
    "        except:\n",
    "            continue\n",
    "    return pd.qcut(scores_array, q=5, labels=False, duplicates='drop')\n",
    "\n",
    "train_df[\"score_bin\"] = create_stratified_bins(train_df[\"score\"].values)\n",
    "\n",
    "train_texts, val_texts, train_scores, val_scores, train_weights, val_weights = train_test_split(\n",
    "    train_df[\"text\"].tolist(),\n",
    "    train_df[\"score\"].tolist(),\n",
    "    sample_weights,\n",
    "    test_size=0.12,\n",
    "    random_state=42,\n",
    "    stratify=train_df[\"score_bin\"]\n",
    ")\n",
    "\n",
    "test_texts = test_df[\"text\"].tolist()\n",
    "\n",
    "print(f\"\\n=== Dataset Splits ===\")\n",
    "print(f\"Train: {len(train_texts)}, Val: {len(val_texts)}, Test: {len(test_texts)}\")\n",
    "print(f\"Val score range: {min(val_scores):.1f} - {max(val_scores):.1f}\")\n",
    "\n",
    "# ============ DATASET ============\n",
    "class LlmScoreDataset(Dataset):\n",
    "    def __init__(self, texts, scores=None, weights=None):\n",
    "        self.texts = list(texts)\n",
    "        self.scores = None if scores is None else list(scores)\n",
    "        self.weights = None if weights is None else list(weights)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {\"text\": self.texts[idx]}\n",
    "        if self.scores is not None:\n",
    "            item[\"score\"] = float(self.scores[idx])\n",
    "        if self.weights is not None:\n",
    "            item[\"weight\"] = float(self.weights[idx])\n",
    "        return item\n",
    "\n",
    "def collate_fn(batch):\n",
    "    texts = [x[\"text\"] for x in batch]\n",
    "    enc = tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    if \"score\" in batch[0]:\n",
    "        scores = torch.tensor([x[\"score\"] for x in batch], dtype=torch.float32)\n",
    "        enc[\"labels\"] = scores\n",
    "    \n",
    "    if \"weight\" in batch[0]:\n",
    "        weights = torch.tensor([x[\"weight\"] for x in batch], dtype=torch.float32)\n",
    "        enc[\"weights\"] = weights\n",
    "    \n",
    "    return enc\n",
    "\n",
    "# ============ SIMPLIFIED MODEL - REGRESSION ONLY ============\n",
    "MODEL_NAME = \"xlm-roberta-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=1\n",
    ")\n",
    "model.config.problem_type = \"regression\"\n",
    "model.to(DEVICE)\n",
    "\n",
    "print(f\"\\n=== Model: {MODEL_NAME} (Pure Regression) ===\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()) / 1e6:.1f}M\")\n",
    "\n",
    "# ============ ADVANCED WEIGHTED LOSS ============\n",
    "class AdaptiveWeightedMSELoss(nn.Module):\n",
    "    \"\"\"MSE with adaptive sample weighting + Huber-like robustness\"\"\"\n",
    "    def __init__(self, delta=1.0):\n",
    "        super().__init__()\n",
    "        self.delta = delta\n",
    "    \n",
    "    def forward(self, predictions, targets, weights=None):\n",
    "        errors = predictions - targets\n",
    "        abs_errors = torch.abs(errors)\n",
    "        \n",
    "        # Huber-like: quadratic for small errors, linear for large\n",
    "        loss = torch.where(\n",
    "            abs_errors < self.delta,\n",
    "            0.5 * errors ** 2,\n",
    "            self.delta * (abs_errors - 0.5 * self.delta)\n",
    "        )\n",
    "        \n",
    "        if weights is not None:\n",
    "            loss = loss * weights\n",
    "        \n",
    "        return loss.mean()\n",
    "\n",
    "criterion = AdaptiveWeightedMSELoss(delta=2.0)\n",
    "\n",
    "# ============ TRAINING CONFIG ============\n",
    "batch_size = 20\n",
    "learning_rate = 3e-5  # Back to standard rate\n",
    "weight_decay = 0.01\n",
    "num_epochs = 8  # More epochs\n",
    "gradient_clip = 1.0\n",
    "\n",
    "train_dataset = LlmScoreDataset(train_texts, train_scores, train_weights)\n",
    "val_dataset   = LlmScoreDataset(val_texts, val_scores, val_weights)\n",
    "test_dataset  = LlmScoreDataset(test_texts, None, None)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print(f\"\\nTrain batches: {len(train_loader)}, Val batches: {len(val_loader)}\")\n",
    "\n",
    "# ============ OPTIMIZER ============\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(0.1 * num_training_steps),\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "# ============ TRAINING ============\n",
    "best_val_rmse = float('inf')\n",
    "best_model_state = None\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "\n",
    "print(\"\\n=== Starting Training ===\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    train_preds, train_labels = [], []\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        weights_batch = batch.pop(\"weights\", None)\n",
    "        labels_batch = batch.pop(\"labels\")\n",
    "        \n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        labels_batch = labels_batch.to(DEVICE)\n",
    "        \n",
    "        if weights_batch is not None:\n",
    "            weights_batch = weights_batch.to(DEVICE)\n",
    "        \n",
    "        outputs = model(**batch)\n",
    "        predictions = outputs.logits.squeeze(-1)\n",
    "        \n",
    "        loss = criterion(predictions, labels_batch, weights_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), gradient_clip)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        train_preds.extend(predictions.detach().cpu().numpy())\n",
    "        train_labels.extend(labels_batch.cpu().numpy())\n",
    "        \n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f\"  Batch {batch_idx+1}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    train_rmse = sqrt(mean_squared_error(train_labels, train_preds))\n",
    "    train_mae = mean_absolute_error(train_labels, train_preds)\n",
    "    \n",
    "    # VALIDATION\n",
    "    model.eval()\n",
    "    val_preds, val_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            weights_batch = batch.pop(\"weights\", None)\n",
    "            labels_batch = batch.pop(\"labels\")\n",
    "            \n",
    "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "            \n",
    "            outputs = model(**batch)\n",
    "            predictions = outputs.logits.squeeze(-1)\n",
    "            \n",
    "            val_preds.extend(predictions.cpu().numpy())\n",
    "            val_labels.extend(labels_batch.numpy())\n",
    "    \n",
    "    val_rmse = sqrt(mean_squared_error(val_labels, val_preds))\n",
    "    val_mae = mean_absolute_error(val_labels, val_preds)\n",
    "    val_preds_array = np.array(val_preds)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train - RMSE: {train_rmse:.4f}, MAE: {train_mae:.4f}\")\n",
    "    print(f\"Val   - RMSE: {val_rmse:.4f}, MAE: {val_mae:.4f}\")\n",
    "    print(f\"Val Preds: Min={val_preds_array.min():.2f}, Max={val_preds_array.max():.2f}, \"\n",
    "          f\"Mean={val_preds_array.mean():.2f}, Std={val_preds_array.std():.2f}\")\n",
    "    \n",
    "    # Show distribution\n",
    "    val_bins = pd.cut(val_preds_array, bins=[0, 3, 5, 7, 9, 10], labels=[\"0-3\", \"3-5\", \"5-7\", \"7-9\", \"9-10\"])\n",
    "    print(f\"Val Pred Distribution: {dict(val_bins.value_counts().sort_index())}\")\n",
    "    \n",
    "    if val_rmse < best_val_rmse:\n",
    "        best_val_rmse = val_rmse\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        patience_counter = 0\n",
    "        print(f\"✓ Best model! (RMSE: {best_val_rmse:.4f})\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"✗ Patience: {patience_counter}/{patience}\")\n",
    "    \n",
    "    if patience_counter >= patience:\n",
    "        print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "# ============ TEST PREDICTION ============\n",
    "print(\"\\n=== Loading Best Model ===\")\n",
    "model.load_state_dict(best_model_state)\n",
    "model.eval()\n",
    "\n",
    "test_preds = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        predictions = outputs.logits.squeeze(-1)\n",
    "        test_preds.extend(predictions.cpu().numpy())\n",
    "\n",
    "test_preds = np.array(test_preds)\n",
    "\n",
    "print(\"\\n=== Test Predictions ===\")\n",
    "print(f\"Range: {test_preds.min():.2f} - {test_preds.max():.2f}\")\n",
    "print(f\"Mean: {test_preds.mean():.2f}, Median: {np.median(test_preds):.2f}, Std: {test_preds.std():.2f}\")\n",
    "\n",
    "print(\"\\nDistribution:\")\n",
    "pred_bins = pd.cut(test_preds, bins=[0, 3, 5, 7, 9, 10], labels=[\"0-3\", \"3-5\", \"5-7\", \"7-9\", \"9-10\"])\n",
    "print(pred_bins.value_counts().sort_index())\n",
    "\n",
    "test_preds = np.clip(test_preds, 0, 10)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": np.arange(1, len(test_preds) + 1),\n",
    "    \"score\": test_preds\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission_improved_final.csv\", index=False)\n",
    "print(\"\\n✓ Submission saved to 'submission_improved_final.csv'\")\n",
    "print(submission.describe())\n",
    "print(\"\\nFirst 30 predictions:\")\n",
    "print(submission.head(30))\n",
    "\n",
    "torch.save(best_model_state, \"best_model_final.pt\")\n",
    "print(\"\\n✓ Model saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c5b13d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Train shape: (5000, 5)\n",
      "Test shape : (3638, 4)\n",
      "\n",
      "=== Label Distribution ===\n",
      "count    5000.000000\n",
      "mean        9.119500\n",
      "std         0.942416\n",
      "min         0.000000\n",
      "25%         9.000000\n",
      "50%         9.000000\n",
      "75%        10.000000\n",
      "max        10.000000\n",
      "Name: score, dtype: float64\n",
      "\n",
      "=== Creating Balanced Dataset ===\n",
      "Range 0-3: 24 samples -> 600 samples\n",
      "Range 3-5: 10 samples -> 600 samples\n",
      "Range 5-7: 46 samples -> 600 samples\n",
      "Range 7-9: 354 samples -> 600 samples\n",
      "Range 9-10.1: 4566 samples -> 600 samples\n",
      "\n",
      "Balanced dataset size: 3000\n",
      "\n",
      "=== Extracting Features for GBDT Models ===\n",
      "Statistical features: 155 features\n",
      "Feature dtypes: [dtype('float64')]\n",
      "\n",
      "=== Extracting TF-IDF Features ===\n",
      "TF-IDF features: 500 features\n",
      "Total GBDT features: 655 features\n",
      "\n",
      "=== Splits ===\n",
      "Train: 2640, Val: 360, Test: 3638\n",
      "\n",
      "======================================================================\n",
      "TRAINING HYBRID ENSEMBLE: TRANSFORMERS + GBDT\n",
      "======================================================================\n",
      "\n",
      "### TRANSFORMER MODELS ###\n",
      "\n",
      "=== Training xlm-roberta-base on text1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1/5: Val RMSE = 2.4537\n",
      "  Epoch 2/5: Val RMSE = 1.8758\n",
      "  Epoch 3/5: Val RMSE = 1.3570\n",
      "  Epoch 4/5: Val RMSE = 1.2634\n",
      "  Epoch 5/5: Val RMSE = 1.2231\n",
      "\n",
      "=== Training xlm-roberta-base on text2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1/5: Val RMSE = 2.7685\n",
      "  Epoch 2/5: Val RMSE = 1.6995\n",
      "  Epoch 3/5: Val RMSE = 1.4051\n",
      "  Epoch 4/5: Val RMSE = 1.4898\n",
      "  Epoch 5/5: Val RMSE = 1.2829\n",
      "\n",
      "=== Training distilbert-base-uncased on text1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1/5: Val RMSE = 2.5913\n",
      "  Epoch 2/5: Val RMSE = 1.3536\n",
      "  Epoch 3/5: Val RMSE = 1.1401\n",
      "  Epoch 4/5: Val RMSE = 0.9405\n",
      "  Epoch 5/5: Val RMSE = 0.7661\n",
      "\n",
      "### GBDT MODELS ###\n",
      "\n",
      "=== Training XGBoost ===\n",
      "[0]\tvalidation_0-rmse:2.99568\n",
      "[50]\tvalidation_0-rmse:2.23644\n",
      "[100]\tvalidation_0-rmse:2.18669\n",
      "[150]\tvalidation_0-rmse:2.16210\n",
      "[200]\tvalidation_0-rmse:2.14594\n",
      "[250]\tvalidation_0-rmse:2.13628\n",
      "[300]\tvalidation_0-rmse:2.13121\n",
      "[350]\tvalidation_0-rmse:2.12757\n",
      "[400]\tvalidation_0-rmse:2.12366\n",
      "[450]\tvalidation_0-rmse:2.12283\n",
      "[499]\tvalidation_0-rmse:2.12101\n",
      "XGBoost Val RMSE: 0.6528\n",
      "\n",
      "=== Training LightGBM ===\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[498]\tvalid_0's l2: 0.513403\n",
      "LightGBM Val RMSE: 0.7165\n",
      "\n",
      "=== Training CatBoost ===\n",
      "Converting sparse matrices to dense for CatBoost...\n",
      "0:\tlearn: 3.0433415\ttest: 2.9998457\tbest: 2.9998457 (0)\ttotal: 54.4ms\tremaining: 27.2s\n",
      "50:\tlearn: 1.4710899\ttest: 1.5080788\tbest: 1.5080788 (50)\ttotal: 309ms\tremaining: 2.72s\n",
      "100:\tlearn: 1.1130258\ttest: 1.2001508\tbest: 1.2001508 (100)\ttotal: 570ms\tremaining: 2.25s\n",
      "150:\tlearn: 0.9052477\ttest: 1.0307655\tbest: 1.0307655 (150)\ttotal: 836ms\tremaining: 1.93s\n",
      "200:\tlearn: 0.7530269\ttest: 0.9282178\tbest: 0.9282178 (200)\ttotal: 1.1s\tremaining: 1.64s\n",
      "250:\tlearn: 0.6337841\ttest: 0.8607750\tbest: 0.8607750 (250)\ttotal: 1.36s\tremaining: 1.35s\n",
      "300:\tlearn: 0.5516699\ttest: 0.8194483\tbest: 0.8194483 (300)\ttotal: 1.64s\tremaining: 1.08s\n",
      "350:\tlearn: 0.4893348\ttest: 0.7887496\tbest: 0.7887496 (350)\ttotal: 1.9s\tremaining: 807ms\n",
      "400:\tlearn: 0.4521760\ttest: 0.7736727\tbest: 0.7736138 (399)\ttotal: 2.17s\tremaining: 535ms\n",
      "450:\tlearn: 0.4198898\ttest: 0.7557637\tbest: 0.7557637 (450)\ttotal: 2.43s\tremaining: 264ms\n",
      "499:\tlearn: 0.3917656\ttest: 0.7421259\tbest: 0.7420044 (498)\ttotal: 2.68s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7420044485\n",
      "bestIteration = 498\n",
      "\n",
      "Shrink model to first 499 iterations.\n",
      "CatBoost Val RMSE: 0.7420\n",
      "\n",
      "=== Generating Predictions from All Models ===\n",
      "Ensemble shape: (3638, 6)\n",
      "\n",
      "=== Computing Optimal Weights ===\n",
      "  XLM-R-1: 1.2231\n",
      "  XLM-R-2: 1.2829\n",
      "  DistilBERT: 0.7661\n",
      "  XGBoost: 0.6528\n",
      "  LightGBM: 0.7165\n",
      "  CatBoost: 0.7420\n",
      "\n",
      "Weights: {'XLM-R-1': np.float64(0.114), 'XLM-R-2': np.float64(0.109), 'DistilBERT': np.float64(0.182), 'XGBoost': np.float64(0.213), 'LightGBM': np.float64(0.194), 'CatBoost': np.float64(0.188)}\n",
      "\n",
      "Weighted Ensemble Val RMSE: 0.7095\n",
      "\n",
      "=== Training Stacking Meta-Learner ===\n",
      "Meta-learner coefficients: {'XLM-R-1': np.float64(0.044), 'XLM-R-2': np.float64(-0.152), 'DistilBERT': np.float64(0.355), 'XGBoost': np.float64(0.775), 'LightGBM': np.float64(0.122), 'CatBoost': np.float64(-0.116)}\n",
      "\n",
      "=== Final Test Predictions ===\n",
      "Range: 1.90 - 10.04\n",
      "Mean: 8.43, Std: 0.73\n",
      "\n",
      "Distribution:\n",
      "0-3        1\n",
      "3-5        6\n",
      "5-7      143\n",
      "7-9     2769\n",
      "9-10     716\n",
      "Name: count, dtype: int64\n",
      "\n",
      "✓ Submission saved to 'submission_hybrid_ensemble.csv'\n",
      "                ID        score\n",
      "count  3638.000000  3638.000000\n",
      "mean   1819.500000     8.429993\n",
      "std    1050.344467     0.732856\n",
      "min       1.000000     1.901129\n",
      "25%     910.250000     8.058424\n",
      "50%    1819.500000     8.561029\n",
      "75%    2728.750000     8.922096\n",
      "max    3638.000000    10.000000\n",
      "\n",
      "Sample predictions:\n",
      "    ID     score\n",
      "0    1  8.649440\n",
      "1    2  8.669762\n",
      "2    3  7.116677\n",
      "3    4  8.963278\n",
      "4    5  8.957698\n",
      "5    6  8.285392\n",
      "6    7  8.520762\n",
      "7    8  8.921072\n",
      "8    9  8.143042\n",
      "9   10  8.945498\n",
      "10  11  7.526366\n",
      "11  12  7.668828\n",
      "12  13  8.813128\n",
      "13  14  8.042481\n",
      "14  15  9.398582\n",
      "15  16  7.627911\n",
      "16  17  9.431278\n",
      "17  18  8.509771\n",
      "18  19  8.117885\n",
      "19  20  8.777623\n",
      "20  21  8.774176\n",
      "21  22  8.217668\n",
      "22  23  7.449480\n",
      "23  24  7.873316\n",
      "24  25  8.253903\n",
      "25  26  8.919168\n",
      "26  27  9.381922\n",
      "27  28  8.573100\n",
      "28  29  8.746259\n",
      "29  30  8.047566\n",
      "\n",
      "======================================================================\n",
      "HYBRID ENSEMBLE COMPLETE!\n",
      "6 Models: 3 Transformers + 3 GBDT\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from math import sqrt\n",
    "\n",
    "# GBDT imports\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "DATA_DIR = Path(\".\")\n",
    "train_path = DATA_DIR / \"train_data.json\"\n",
    "test_path  = DATA_DIR / \"test_data.json\"\n",
    "\n",
    "def load_json_any(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        txt = f.read().strip()\n",
    "        if not txt:\n",
    "            return []\n",
    "        if \"\\n\" in txt and txt.lstrip().startswith(\"{\") and not txt.lstrip().startswith(\"[\"):\n",
    "            return [json.loads(line) for line in txt.splitlines() if line.strip()]\n",
    "        return json.loads(txt)\n",
    "\n",
    "train_raw = load_json_any(train_path)\n",
    "test_raw  = load_json_any(test_path)\n",
    "\n",
    "train_df = pd.DataFrame(train_raw)\n",
    "test_df  = pd.DataFrame(test_raw)\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape :\", test_df.shape)\n",
    "\n",
    "# ============ TEXT PREPROCESSING ============\n",
    "def advanced_text_preprocessing(text):\n",
    "    \"\"\"Advanced text cleaning\"\"\"\n",
    "    if pd.isna(text) or text is None:\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.replace('\"', '\"').replace('\"', '\"')\n",
    "    text = re.sub(r'[^\\w\\s.,!?;:\\-\\(\\)\\[\\]]', '', text)\n",
    "    text = re.sub(r'\\b\\d{4,}\\b', ' NUM ', text)\n",
    "    text = re.sub(r'([.!?]){2,}', r'\\1', text)\n",
    "    return text.strip().lower()\n",
    "\n",
    "# Apply preprocessing\n",
    "for df in (train_df, test_df):\n",
    "    if \"system_prompt\" not in df:\n",
    "        df[\"system_prompt\"] = \"\"\n",
    "    else:\n",
    "        df[\"system_prompt\"] = df[\"system_prompt\"].fillna(\"\")\n",
    "    \n",
    "    df[\"response\"] = df[\"response\"].fillna(\"\").astype(str)\n",
    "    df[\"user_prompt\"] = df[\"user_prompt\"].fillna(\"\").astype(str)\n",
    "    df[\"system_prompt\"] = df[\"system_prompt\"].fillna(\"\").astype(str)\n",
    "    \n",
    "    df[\"response_clean\"] = df[\"response\"].apply(advanced_text_preprocessing)\n",
    "    df[\"user_prompt_clean\"] = df[\"user_prompt\"].apply(advanced_text_preprocessing)\n",
    "    df[\"system_prompt_clean\"] = df[\"system_prompt\"].apply(advanced_text_preprocessing)\n",
    "\n",
    "train_df[\"score\"] = train_df[\"score\"].astype(float)\n",
    "\n",
    "print(\"\\n=== Label Distribution ===\")\n",
    "print(train_df[\"score\"].describe())\n",
    "\n",
    "# ============ SUPER AGGRESSIVE BALANCED OVERSAMPLING ============\n",
    "def create_balanced_dataset(df, target_col='score', samples_per_range=600):\n",
    "    \"\"\"Create perfectly balanced dataset\"\"\"\n",
    "    print(\"\\n=== Creating Balanced Dataset ===\")\n",
    "    \n",
    "    ranges = [(0, 3), (3, 5), (5, 7), (7, 9), (9, 10.1)]\n",
    "    balanced_dfs = []\n",
    "    \n",
    "    for low, high in ranges:\n",
    "        range_df = df[(df[target_col] >= low) & (df[target_col] < high)].copy()\n",
    "        n_current = len(range_df)\n",
    "        \n",
    "        print(f\"Range {low}-{high}: {n_current} samples\", end=\" -> \")\n",
    "        \n",
    "        if n_current == 0:\n",
    "            template_df = df[(df[target_col] >= 7) & (df[target_col] < 9)].sample(min(30, len(df)))\n",
    "            for _ in range(samples_per_range // 30):\n",
    "                synthetic = template_df.copy()\n",
    "                synthetic[target_col] = np.random.uniform(low, min(high, 10), len(synthetic))\n",
    "                balanced_dfs.append(synthetic)\n",
    "            print(f\"{samples_per_range} samples (synthetic)\")\n",
    "        else:\n",
    "            n_repeats = samples_per_range // n_current\n",
    "            for _ in range(n_repeats):\n",
    "                aug_df = range_df.copy()\n",
    "                noise = np.random.normal(0, 0.15, len(aug_df))\n",
    "                aug_df[target_col] = np.clip(aug_df[target_col] + noise, low, min(high, 10))\n",
    "                balanced_dfs.append(aug_df)\n",
    "            \n",
    "            remainder = samples_per_range % n_current\n",
    "            if remainder > 0:\n",
    "                balanced_dfs.append(range_df.sample(remainder, replace=True))\n",
    "            print(f\"{samples_per_range} samples\")\n",
    "    \n",
    "    result = pd.concat(balanced_dfs, ignore_index=True)\n",
    "    print(f\"\\nBalanced dataset size: {len(result)}\")\n",
    "    return result\n",
    "\n",
    "train_df = create_balanced_dataset(train_df, target_col='score', samples_per_range=600)\n",
    "\n",
    "# ============ BUILD TEXT FORMATS ============\n",
    "def build_text_format1(df):\n",
    "    return (\n",
    "        \"[RATE 0-10] \" + df[\"metric_name\"].astype(str) + \": \"\n",
    "        + df[\"response_clean\"].astype(str) + \" [USER: \" + df[\"user_prompt_clean\"].astype(str) + \"]\"\n",
    "    )\n",
    "\n",
    "def build_text_format2(df):\n",
    "    return (\n",
    "        \"Evaluate \" + df[\"metric_name\"].astype(str) + \". \"\n",
    "        + \"System: \" + df[\"system_prompt_clean\"].astype(str) + \". \"\n",
    "        + \"User: \" + df[\"user_prompt_clean\"].astype(str) + \". \"\n",
    "        + \"Response: \" + df[\"response_clean\"].astype(str)\n",
    "    )\n",
    "\n",
    "train_df[\"text1\"] = build_text_format1(train_df)\n",
    "train_df[\"text2\"] = build_text_format2(train_df)\n",
    "\n",
    "test_df[\"text1\"] = build_text_format1(test_df)\n",
    "test_df[\"text2\"] = build_text_format2(test_df)\n",
    "\n",
    "# ============ EXTRACT FEATURES FOR GBDT MODELS ============\n",
    "print(\"\\n=== Extracting Features for GBDT Models ===\")\n",
    "\n",
    "def extract_statistical_features(df):\n",
    "    \"\"\"Extract statistical features - FIXED to ensure numeric types\"\"\"\n",
    "    features = pd.DataFrame()\n",
    "    \n",
    "    # Length features\n",
    "    features['resp_len'] = df['response'].str.len().astype(float)\n",
    "    features['resp_words'] = df['response'].str.split().str.len().astype(float)\n",
    "    features['user_len'] = df['user_prompt'].str.len().astype(float)\n",
    "    features['user_words'] = df['user_prompt'].str.split().str.len().astype(float)\n",
    "    \n",
    "    # Ratio features\n",
    "    features['len_ratio'] = (features['resp_len'] / (features['user_len'] + 1)).astype(float)\n",
    "    features['word_ratio'] = (features['resp_words'] / (features['user_words'] + 1)).astype(float)\n",
    "    \n",
    "    # Punctuation features\n",
    "    features['punct_count'] = df['response'].str.count(r'[.,!?;:]').astype(float)\n",
    "    features['punct_density'] = (features['punct_count'] / (features['resp_len'] + 1)).astype(float)\n",
    "    \n",
    "    # Uppercase features\n",
    "    features['upper_count'] = df['response'].str.count(r'[A-Z]').astype(float)\n",
    "    features['upper_ratio'] = (features['upper_count'] / (features['resp_len'] + 1)).astype(float)\n",
    "    \n",
    "    # Average word length\n",
    "    features['avg_word_len'] = (features['resp_len'] / (features['resp_words'] + 1)).astype(float)\n",
    "    \n",
    "    # Sentence count\n",
    "    features['sentences'] = df['response'].str.count(r'[.!?]+').astype(float)\n",
    "    \n",
    "    # Question marks\n",
    "    features['question_marks'] = df['response'].str.count(r'\\?').astype(float)\n",
    "    \n",
    "    # Metric encoding (one-hot) - FIXED: ensure numeric\n",
    "    metric_dummies = pd.get_dummies(df['metric_name'], prefix='metric', dtype=float)\n",
    "    features = pd.concat([features, metric_dummies], axis=1)\n",
    "    \n",
    "    # Fill NaN with 0\n",
    "    features = features.fillna(0.0)\n",
    "    \n",
    "    # CRITICAL: Ensure all columns are numeric\n",
    "    for col in features.columns:\n",
    "        features[col] = pd.to_numeric(features[col], errors='coerce').fillna(0.0)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Extract statistical features\n",
    "train_stat_features = extract_statistical_features(train_df)\n",
    "test_stat_features = extract_statistical_features(test_df)\n",
    "\n",
    "# Ensure test has same columns as train\n",
    "for col in train_stat_features.columns:\n",
    "    if col not in test_stat_features.columns:\n",
    "        test_stat_features[col] = 0.0\n",
    "\n",
    "test_stat_features = test_stat_features[train_stat_features.columns]\n",
    "\n",
    "print(f\"Statistical features: {train_stat_features.shape[1]} features\")\n",
    "print(f\"Feature dtypes: {train_stat_features.dtypes.unique()}\")\n",
    "\n",
    "# ============ TF-IDF FEATURES FOR GBDT ============\n",
    "print(\"\\n=== Extracting TF-IDF Features ===\")\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=500,\n",
    "    ngram_range=(1, 3),\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "train_tfidf = tfidf.fit_transform(train_df['text1'])\n",
    "test_tfidf = tfidf.transform(test_df['text1'])\n",
    "\n",
    "print(f\"TF-IDF features: {train_tfidf.shape[1]} features\")\n",
    "\n",
    "# Combine all features for GBDT - FIXED\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "train_gbdt_features = hstack([\n",
    "    csr_matrix(train_stat_features.values.astype(np.float32)),\n",
    "    train_tfidf\n",
    "])\n",
    "\n",
    "test_gbdt_features = hstack([\n",
    "    csr_matrix(test_stat_features.values.astype(np.float32)),\n",
    "    test_tfidf\n",
    "])\n",
    "\n",
    "print(f\"Total GBDT features: {train_gbdt_features.shape[1]} features\")\n",
    "\n",
    "# ============ SPLIT DATA ============\n",
    "def create_bins(scores):\n",
    "    return pd.qcut(scores, q=5, labels=False, duplicates='drop')\n",
    "\n",
    "train_df[\"bin\"] = create_bins(train_df[\"score\"])\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(train_df)),\n",
    "    test_size=0.12,\n",
    "    random_state=42,\n",
    "    stratify=train_df[\"bin\"]\n",
    ")\n",
    "\n",
    "train_data = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "val_data = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "# Split GBDT features\n",
    "X_train_gbdt = train_gbdt_features[train_idx]\n",
    "X_val_gbdt = train_gbdt_features[val_idx]\n",
    "y_train = train_data[\"score\"].values\n",
    "y_val = val_data[\"score\"].values\n",
    "\n",
    "print(f\"\\n=== Splits ===\")\n",
    "print(f\"Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_df)}\")\n",
    "\n",
    "# ============ TRANSFORMER MODEL TRAINER ============\n",
    "class TransformerRegressor:\n",
    "    \"\"\"Wrapper for transformer-based regression\"\"\"\n",
    "    def __init__(self, model_name, text_col='text1', max_length=512):\n",
    "        self.model_name = model_name\n",
    "        self.text_col = text_col\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = None\n",
    "        self.model = None\n",
    "    \n",
    "    def train(self, train_data, val_data, epochs=5, batch_size=20, lr=3e-5):\n",
    "        \"\"\"Train transformer model\"\"\"\n",
    "        print(f\"\\n=== Training {self.model_name} on {self.text_col} ===\")\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            self.model_name, num_labels=1\n",
    "        )\n",
    "        self.model.config.problem_type = \"regression\"\n",
    "        self.model.to(DEVICE)\n",
    "        \n",
    "        class SimpleDataset(Dataset):\n",
    "            def __init__(self, texts, scores):\n",
    "                self.texts = texts\n",
    "                self.scores = scores\n",
    "            def __len__(self):\n",
    "                return len(self.texts)\n",
    "            def __getitem__(self, idx):\n",
    "                return {\"text\": self.texts[idx], \"score\": self.scores[idx]}\n",
    "        \n",
    "        def collate_fn(batch):\n",
    "            texts = [x[\"text\"] for x in batch]\n",
    "            enc = self.tokenizer(texts, padding=True, truncation=True, \n",
    "                                max_length=self.max_length, return_tensors=\"pt\")\n",
    "            enc[\"labels\"] = torch.tensor([x[\"score\"] for x in batch], dtype=torch.float32)\n",
    "            return enc\n",
    "        \n",
    "        train_dataset = SimpleDataset(train_data[self.text_col].tolist(), \n",
    "                                     train_data[\"score\"].tolist())\n",
    "        val_dataset = SimpleDataset(val_data[self.text_col].tolist(), \n",
    "                                   val_data[\"score\"].tolist())\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "        \n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=lr, weight_decay=0.01)\n",
    "        num_training_steps = epochs * len(train_loader)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=int(0.1 * num_training_steps), \n",
    "            num_training_steps=num_training_steps\n",
    "        )\n",
    "        \n",
    "        best_val_rmse = float('inf')\n",
    "        best_state = None\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            for batch in train_loader:\n",
    "                labels = batch.pop(\"labels\").to(DEVICE)\n",
    "                batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "                \n",
    "                outputs = self.model(**batch)\n",
    "                preds = outputs.logits.squeeze(-1)\n",
    "                loss = nn.MSELoss()(preds, labels)\n",
    "                \n",
    "                loss.backward()\n",
    "                clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            # Validation\n",
    "            self.model.eval()\n",
    "            val_preds, val_labels = [], []\n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    labels = batch.pop(\"labels\")\n",
    "                    batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "                    outputs = self.model(**batch)\n",
    "                    val_preds.extend(outputs.logits.squeeze(-1).cpu().numpy())\n",
    "                    val_labels.extend(labels.numpy())\n",
    "            \n",
    "            val_rmse = sqrt(mean_squared_error(val_labels, val_preds))\n",
    "            print(f\"  Epoch {epoch+1}/{epochs}: Val RMSE = {val_rmse:.4f}\")\n",
    "            \n",
    "            if val_rmse < best_val_rmse:\n",
    "                best_val_rmse = val_rmse\n",
    "                best_state = self.model.state_dict().copy()\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            if patience_counter >= 3:\n",
    "                print(f\"  Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "        \n",
    "        if best_state is not None:\n",
    "            self.model.load_state_dict(best_state)\n",
    "        \n",
    "        return best_val_rmse\n",
    "    \n",
    "    def predict(self, data, batch_size=20):\n",
    "        \"\"\"Predict scores\"\"\"\n",
    "        class SimpleDataset(Dataset):\n",
    "            def __init__(self, texts):\n",
    "                self.texts = texts\n",
    "            def __len__(self):\n",
    "                return len(self.texts)\n",
    "            def __getitem__(self, idx):\n",
    "                return self.texts[idx]\n",
    "        \n",
    "        def collate_fn(batch):\n",
    "            return self.tokenizer(batch, padding=True, truncation=True, \n",
    "                                 max_length=self.max_length, return_tensors=\"pt\")\n",
    "        \n",
    "        dataset = SimpleDataset(data[self.text_col].tolist())\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "        \n",
    "        self.model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in loader:\n",
    "                batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "                outputs = self.model(**batch)\n",
    "                preds.extend(outputs.logits.squeeze(-1).cpu().numpy())\n",
    "        \n",
    "        return np.array(preds)\n",
    "\n",
    "# ============ TRAIN ENSEMBLE ============\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING HYBRID ENSEMBLE: TRANSFORMERS + GBDT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============ PART 1: TRANSFORMER MODELS ============\n",
    "print(\"\\n### TRANSFORMER MODELS ###\")\n",
    "\n",
    "# Transformer 1\n",
    "trans1 = TransformerRegressor(\"xlm-roberta-base\", text_col='text1', max_length=512)\n",
    "rmse_trans1 = trans1.train(train_data, val_data, epochs=5, batch_size=20, lr=3e-5)\n",
    "\n",
    "# Transformer 2\n",
    "trans2 = TransformerRegressor(\"xlm-roberta-base\", text_col='text2', max_length=450)\n",
    "rmse_trans2 = trans2.train(train_data, val_data, epochs=5, batch_size=22, lr=2.5e-5)\n",
    "\n",
    "# Transformer 3\n",
    "trans3 = TransformerRegressor(\"distilbert-base-uncased\", text_col='text1', max_length=512)\n",
    "rmse_trans3 = trans3.train(train_data, val_data, epochs=5, batch_size=24, lr=4e-5)\n",
    "\n",
    "# ============ PART 2: GBDT MODELS ============\n",
    "print(\"\\n### GBDT MODELS ###\")\n",
    "\n",
    "# XGBoost\n",
    "print(\"\\n=== Training XGBoost ===\")\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    min_child_weight=3,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    gamma=0.1,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=42,\n",
    "    tree_method='hist',\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "xgb_model.fit(\n",
    "    X_train_gbdt, y_train,\n",
    "    eval_set=[(X_val_gbdt, y_val)],\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "val_pred_xgb = xgb_model.predict(X_val_gbdt)\n",
    "rmse_xgb = sqrt(mean_squared_error(y_val, val_pred_xgb))\n",
    "print(f\"XGBoost Val RMSE: {rmse_xgb:.4f}\")\n",
    "\n",
    "# LightGBM\n",
    "print(\"\\n=== Training LightGBM ===\")\n",
    "lgb_model = lgb.LGBMRegressor(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=7,\n",
    "    num_leaves=50,\n",
    "    min_child_samples=20,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=42,\n",
    "    force_col_wise=True,\n",
    "    verbosity=-1\n",
    ")\n",
    "\n",
    "lgb_model.fit(\n",
    "    X_train_gbdt, y_train,\n",
    "    eval_set=[(X_val_gbdt, y_val)],\n",
    "    callbacks=[lgb.early_stopping(50)]\n",
    ")\n",
    "\n",
    "val_pred_lgb = lgb_model.predict(X_val_gbdt)\n",
    "rmse_lgb = sqrt(mean_squared_error(y_val, val_pred_lgb))\n",
    "print(f\"LightGBM Val RMSE: {rmse_lgb:.4f}\")\n",
    "\n",
    "# ============ CatBoost - FIXED ============\n",
    "print(\"\\n=== Training CatBoost ===\")\n",
    "\n",
    "# Convert sparse matrices to dense for CatBoost (more stable)\n",
    "print(\"Converting sparse matrices to dense for CatBoost...\")\n",
    "X_train_gbdt_dense = X_train_gbdt.toarray()\n",
    "X_val_gbdt_dense = X_val_gbdt.toarray()\n",
    "test_gbdt_features_dense = test_gbdt_features.toarray()\n",
    "\n",
    "cat_model = CatBoostRegressor(\n",
    "    iterations=500,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    l2_leaf_reg=3.0,\n",
    "    subsample=0.8,\n",
    "    random_state=42,\n",
    "    verbose=50,\n",
    "    early_stopping_rounds=50,\n",
    "    thread_count=32  # FIXED: Explicitly set thread count\n",
    ")\n",
    "\n",
    "cat_model.fit(\n",
    "    X_train_gbdt_dense, y_train,\n",
    "    eval_set=(X_val_gbdt_dense, y_val)\n",
    ")\n",
    "\n",
    "val_pred_cat = cat_model.predict(X_val_gbdt_dense)\n",
    "rmse_cat = sqrt(mean_squared_error(y_val, val_pred_cat))\n",
    "print(f\"CatBoost Val RMSE: {rmse_cat:.4f}\")\n",
    "\n",
    "# ============ GENERATE ALL PREDICTIONS ============\n",
    "print(\"\\n=== Generating Predictions from All Models ===\")\n",
    "\n",
    "# Validation predictions\n",
    "val_pred_trans1 = trans1.predict(val_data)\n",
    "val_pred_trans2 = trans2.predict(val_data)\n",
    "val_pred_trans3 = trans3.predict(val_data)\n",
    "\n",
    "# Test predictions - Transformers\n",
    "test_pred_trans1 = trans1.predict(test_df)\n",
    "test_pred_trans2 = trans2.predict(test_df)\n",
    "test_pred_trans3 = trans3.predict(test_df)\n",
    "\n",
    "# Test predictions - GBDT\n",
    "test_pred_xgb = xgb_model.predict(test_gbdt_features)\n",
    "test_pred_lgb = lgb_model.predict(test_gbdt_features)\n",
    "test_pred_cat = cat_model.predict(test_gbdt_features_dense)  # FIXED: Use dense version\n",
    "\n",
    "# Stack all predictions\n",
    "val_preds_all = np.column_stack([\n",
    "    val_pred_trans1, val_pred_trans2, val_pred_trans3,\n",
    "    val_pred_xgb, val_pred_lgb, val_pred_cat\n",
    "])\n",
    "\n",
    "test_preds_all = np.column_stack([\n",
    "    test_pred_trans1, test_pred_trans2, test_pred_trans3,\n",
    "    test_pred_xgb, test_pred_lgb, test_pred_cat\n",
    "])\n",
    "\n",
    "print(f\"Ensemble shape: {test_preds_all.shape}\")\n",
    "\n",
    "# ============ WEIGHTED ENSEMBLE ============\n",
    "print(\"\\n=== Computing Optimal Weights ===\")\n",
    "\n",
    "rmses = np.array([rmse_trans1, rmse_trans2, rmse_trans3, rmse_xgb, rmse_lgb, rmse_cat])\n",
    "model_names = [\"XLM-R-1\", \"XLM-R-2\", \"DistilBERT\", \"XGBoost\", \"LightGBM\", \"CatBoost\"]\n",
    "\n",
    "for name, rmse in zip(model_names, rmses):\n",
    "    print(f\"  {name}: {rmse:.4f}\")\n",
    "\n",
    "# Inverse RMSE weighting\n",
    "weights = 1.0 / rmses\n",
    "weights = weights / weights.sum()\n",
    "\n",
    "print(f\"\\nWeights: {dict(zip(model_names, weights.round(3)))}\")\n",
    "\n",
    "# Weighted average\n",
    "val_pred_weighted = (val_preds_all * weights).sum(axis=1)\n",
    "test_pred_weighted = (test_preds_all * weights).sum(axis=1)\n",
    "\n",
    "val_rmse_weighted = sqrt(mean_squared_error(y_val, val_pred_weighted))\n",
    "print(f\"\\nWeighted Ensemble Val RMSE: {val_rmse_weighted:.4f}\")\n",
    "\n",
    "# ============ STACKING WITH META-LEARNER ============\n",
    "print(\"\\n=== Training Stacking Meta-Learner ===\")\n",
    "\n",
    "meta_learner = Ridge(alpha=0.5)\n",
    "meta_learner.fit(val_preds_all, y_val)\n",
    "\n",
    "test_pred_stacked = meta_learner.predict(test_preds_all)\n",
    "\n",
    "print(f\"Meta-learner coefficients: {dict(zip(model_names, meta_learner.coef_.round(3)))}\")\n",
    "\n",
    "# ============ FINAL HYBRID ENSEMBLE ============\n",
    "test_pred_final = 0.5 * test_pred_weighted + 0.5 * test_pred_stacked\n",
    "\n",
    "print(\"\\n=== Final Test Predictions ===\")\n",
    "print(f\"Range: {test_pred_final.min():.2f} - {test_pred_final.max():.2f}\")\n",
    "print(f\"Mean: {test_pred_final.mean():.2f}, Std: {test_pred_final.std():.2f}\")\n",
    "\n",
    "# Distribution\n",
    "pred_bins = pd.cut(test_pred_final, bins=[0, 3, 5, 7, 9, 10], labels=[\"0-3\", \"3-5\", \"5-7\", \"7-9\", \"9-10\"])\n",
    "print(\"\\nDistribution:\")\n",
    "print(pred_bins.value_counts().sort_index())\n",
    "\n",
    "# Clip\n",
    "test_pred_final = np.clip(test_pred_final, 0, 10)\n",
    "\n",
    "# ============ SAVE SUBMISSION ============\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": np.arange(1, len(test_pred_final) + 1),\n",
    "    \"score\": test_pred_final\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission_hybrid_ensemble.csv\", index=False)\n",
    "print(\"\\n✓ Submission saved to 'submission_hybrid_ensemble.csv'\")\n",
    "print(submission.describe())\n",
    "print(\"\\nSample predictions:\")\n",
    "print(submission.head(30))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HYBRID ENSEMBLE COMPLETE!\")\n",
    "print(\"6 Models: 3 Transformers + 3 GBDT\")\n",
    "print(\"=\"*70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coloc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
